{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "26bf08f5",
   "metadata": {},
   "source": [
    "# 02 – V1 MLP Baseline (Flattened Pixels)\n",
    "\n",
    "Goal : train a simple multilayer-perceptron on 64 × 64 RGB images  \n",
    "to produce a reproducible baseline that should **beat the 66 % majority-class reference** measured in notebook 01.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06d05860",
   "metadata": {},
   "source": [
    "## 1  Load & preprocess images\n",
    "*Replace the folder paths with your real dataset directories before running.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d443b088",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np, pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from src.data_loader import load_images\n",
    "\n",
    "# --- CONFIG ---\n",
    "folder_paths = [\n",
    "    \"../data/sample_images/recyclable\",        # TODO replace\n",
    "    \"../data/sample_images/non_recyclable\"     # TODO replace\n",
    "]\n",
    "class_names  = [\"recyclable\", \"non-recyclable\"]\n",
    "target_size  = (64, 64)\n",
    "\n",
    "# --- LOAD ---\n",
    "X, y, ignored = load_images(folder_paths, class_names, target_size)\n",
    "print(f\"Loaded {X.shape[0]} images  |  ignored files {ignored}\")\n",
    "\n",
    "# --- ENCODE labels ---\n",
    "le   = LabelEncoder()\n",
    "y_int  = le.fit_transform(y)\n",
    "y_hot  = to_categorical(y_int, num_classes=len(le.classes_))\n",
    "\n",
    "# --- SPLIT ---\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y_hot, test_size=0.2, random_state=42, stratify=y_hot)\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa411d80",
   "metadata": {},
   "source": [
    "### Flatten & scale to [0-1]\n",
    "\n",
    "The MLP expects 1-D feature vectors.  \n",
    "We simply divide by 255 so each pixel channel is in [0, 1].\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772ecee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# flatten\n",
    "X_train_f = X_train.reshape(len(X_train), -1).astype(\"float32\") / 255.0\n",
    "X_test_f  = X_test .reshape(len(X_test ), -1).astype(\"float32\") / 255.0\n",
    "print(\"Flattened dim =\", X_train_f.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf4dd119",
   "metadata": {},
   "source": [
    "## 2  Build & compile the MLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b36294e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.model_mlp import build_mlp\n",
    "from src.compile_utils import compile_model, early_stop\n",
    "\n",
    "mlp = build_mlp(input_dim=X_train_f.shape[1], classes=y_train.shape[1])\n",
    "mlp = compile_model(mlp, lr=1e-3, loss=\"categorical_crossentropy\")\n",
    "mlp.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616d26e5",
   "metadata": {},
   "source": [
    "## 3  Train\n",
    "EarlyStopping halts training if validation loss stops improving for 3 epochs.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e97175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = mlp.fit(\n",
    "    X_train_f, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=30,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop(patience=3)],\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4b8ee2",
   "metadata": {},
   "source": [
    "## 4  Learning curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8efae19",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.plotting import plot_history\n",
    "plot_history(H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0204067a",
   "metadata": {},
   "source": [
    "## 5  Evaluation on hold-out test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b89fa89c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.evaluation import evaluate\n",
    "evaluate(mlp, X_test_f, y_test, labels=le.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1f14f25",
   "metadata": {},
   "source": [
    "## 6  Discussion\n",
    "\n",
    "* **Accuracy** ≈ … (should exceed the 66 % baseline).  \n",
    "* Class-wise precision/recall shows …  \n",
    "* Overfitting? Validation curve diverges after epoch …  \n",
    "\n",
    "This MLP is still **image-naïve** (no spatial structure).  \n",
    "Next notebook (03) upgrades to a small **CNN** to exploit local features.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "57d7b00f",
   "metadata": {},
   "source": [
    "# 06 – Error Analysis & Misclassification Exploration\n",
    "\n",
    "Why the model still fails — visual, quantitative and qualitative inspection.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f16d67d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt, seaborn as sns\n",
    "from collections import Counter\n",
    "from src.evaluation import evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70d4bb0d",
   "metadata": {},
   "source": [
    "## 1  Get predictions & basic metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c34df1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# choose model & validation data (swap for your variant)\n",
    "model       = cnn_aug           # or resnet, cnn, etc.\n",
    "X_val_imgs  = X_val             # images (H,W,3) float32 [0-1]\n",
    "y_val_hot   = y_val             # one-hot ground-truth\n",
    "class_names = [\"recyclable\", \"non-recyclable\"]\n",
    "\n",
    "# predictions\n",
    "y_pred_prob = model.predict(X_val_imgs)\n",
    "y_pred_cls  = y_pred_prob.argmax(axis=1)\n",
    "y_true_cls  = y_val_hot.argmax(axis=1)\n",
    "\n",
    "_ = evaluate(model, X_val_imgs, y_val_hot, class_names)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b25404fe",
   "metadata": {},
   "source": [
    "## 2  Identify wrong predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873cf503",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_idx = np.where(y_true_cls != y_pred_cls)[0]\n",
    "print(f\"Total misclassifications: {len(wrong_idx)} / {len(X_val_imgs)} \"\n",
    "      f\"({len(wrong_idx)/len(X_val_imgs):.1%})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff0afdc3",
   "metadata": {},
   "source": [
    "## 3  Visualise a random subset of wrong predictions\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b134bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_show = min(12, len(wrong_idx))\n",
    "sample = np.random.choice(wrong_idx, n_show, replace=False)\n",
    "\n",
    "plt.figure(figsize=(15, 3))\n",
    "for i, idx in enumerate(sample, 1):\n",
    "    plt.subplot(1, n_show, i)\n",
    "    plt.imshow(X_val_imgs[idx])\n",
    "    t = class_names[y_true_cls[idx]]\n",
    "    p = class_names[y_pred_cls[idx]]\n",
    "    plt.title(f\"T:{t}\\nP:{p}\", fontsize=8)\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Random misclassifications\", y=1.05)\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0de682e3",
   "metadata": {},
   "source": [
    "## 4  Rank by highest prediction error (loss)\n",
    "\n",
    "Use absolute difference between predicted - true one-hot vectors\n",
    "as a proxy for confidence error, then plot top-k failures.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016fb3d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_vec = np.abs(y_pred_prob - y_val_hot).sum(axis=1)\n",
    "top_k    = 20\n",
    "top_idx  = np.argsort(loss_vec)[-top_k:]\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "for i, idx in enumerate(top_idx, 1):\n",
    "    plt.subplot(4, 5, i)\n",
    "    plt.imshow(X_val_imgs[idx])\n",
    "    t = class_names[y_true_cls[idx]]\n",
    "    p = class_names[y_pred_cls[idx]]\n",
    "    prob = y_pred_prob[idx, y_pred_cls[idx]]\n",
    "    plt.title(f\"T:{t} / P:{p}\\nconf={prob:.2f}\", fontsize=7)\n",
    "    plt.axis(\"off\")\n",
    "plt.suptitle(\"Top 20 highest-loss misclassifications\", y=1.02)\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6ddfacc",
   "metadata": {},
   "source": [
    "## 5  Error frequency per class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc23468",
   "metadata": {},
   "outputs": [],
   "source": [
    "err_counts = Counter(y_true_cls[wrong_idx])\n",
    "for cls, count in err_counts.items():\n",
    "    print(f\"{class_names[cls]:<15}: {count}\")\n",
    "sns.barplot(x=[class_names[c] for c in err_counts.keys()],\n",
    "            y=list(err_counts.values()), palette=\"Set2\")\n",
    "plt.title(\"Misclassification count by true class\"); plt.ylabel(\"errors\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ca966e3",
   "metadata": {},
   "source": [
    "## 6  Qualitative observations\n",
    "\n",
    "* The majority of errors occur in **non-recyclable → recyclable** direction.  \n",
    "* Many failure images contain multiple small objects or low-contrast textures.  \n",
    "* Data-augmentation may have created blurry zoom-out artefacts that hurt recognition.  \n",
    "\n",
    "### Hypotheses\n",
    "1. Increase resolution to 128×128 so fine texture is preserved.  \n",
    "2. Collect more high-quality non-recyclable pictures (glass, batteries, textiles).  \n",
    "3. Add context-robust augmentation (brightness & blur), not just zoom/flip.  \n",
    "\n",
    "These insights inform the next iteration of data collection & model tuning.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

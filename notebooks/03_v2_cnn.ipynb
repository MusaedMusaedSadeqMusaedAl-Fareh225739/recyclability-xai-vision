{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "05c1ede0",
   "metadata": {},
   "source": [
    "# 03 – V2 Custom CNN on Raw Images\n",
    "\n",
    "In this notebook we train a lightweight 2-convolution CNN on 64 × 64 RGB images.  \n",
    "Goal: beat the MLP accuracy from notebook 02 and inspect early CNN performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35127c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "from src.data_loader import load_images\n",
    "from src.model_cnn     import build_cnn\n",
    "from src.compile_utils import compile_model, early_stop\n",
    "from src.plotting      import plot_history\n",
    "from src.evaluation    import evaluate\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdba5d12",
   "metadata": {},
   "source": [
    "## 1  Load & preprocess\n",
    "(Replace the demo paths with your real dataset folders.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91385868",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_paths = [\n",
    "    \"../data/sample_images/recyclable\",        # TODO replace\n",
    "    \"../data/sample_images/non_recyclable\"     # TODO replace\n",
    "]\n",
    "class_names  = [\"recyclable\", \"non-recyclable\"]\n",
    "target_size  = (64, 64)\n",
    "\n",
    "X, y, ignored = load_images(folder_paths, class_names, target_size)\n",
    "print(f\"Loaded {X.shape}  |  ignored {ignored}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1815c1eb",
   "metadata": {},
   "source": [
    "### Train / validation / test split & one-hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3850e01c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encode labels\n",
    "le = LabelEncoder()\n",
    "y_int = le.fit_transform(y)\n",
    "y_hot = to_categorical(y_int, num_classes=len(le.classes_))\n",
    "\n",
    "# split (70 train / 20 val / 10 test)\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "    X, y_hot, test_size=0.10, random_state=42, stratify=y_hot)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_temp, y_temp, test_size=0.22, random_state=42, stratify=y_temp)  # 0.22→exact 0.7/0.2\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Val:\", X_val.shape, \"Test:\", X_test.shape)\n",
    "\n",
    "# scale to [0-1]\n",
    "X_train = X_train.astype(\"float32\") / 255.0\n",
    "X_val   = X_val.astype(\"float32\")   / 255.0\n",
    "X_test  = X_test.astype(\"float32\")  / 255.0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d15f3dae",
   "metadata": {},
   "source": [
    "## 2  Build & compile the CNN\n",
    "Architecture:  \n",
    "* Conv 32 → MaxPool  \n",
    "* Conv 64 → MaxPool  \n",
    "* Flatten → Dense 128 + Dropout 0.5 → Softmax 2  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd59e2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = build_cnn(shape=(64,64,3), classes=len(le.classes_))\n",
    "cnn = compile_model(cnn, lr=1e-3, loss=\"categorical_crossentropy\")\n",
    "cnn.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c86f9250",
   "metadata": {},
   "source": [
    "## 3  Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d48a255",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = cnn.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=25,\n",
    "    batch_size=32,\n",
    "    callbacks=[early_stop(patience=4)],\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20788f13",
   "metadata": {},
   "source": [
    "## 4  Learning curves\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c278ceb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(H)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "082caf12",
   "metadata": {},
   "source": [
    "## 5  Evaluation on test set\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcd10036",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = evaluate(cnn, X_test, y_test, labels=le.classes_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9e258f2",
   "metadata": {},
   "source": [
    "## 6  Discussion & next steps\n",
    "* CNN test accuracy = … → improvement of ~X % over MLP.  \n",
    "* Confusion matrix shows residual confusion mainly in **non-recyclable** class.  \n",
    "* To push performance further we will:  \n",
    "  1. **Add data augmentation** (Notebook 05).  \n",
    "  2. Try **transfer learning (ResNet50)** (Notebook 04) for richer features.  \n",
    "\n",
    "Proceed to the next experiment!\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1762d06a",
   "metadata": {},
   "source": [
    "# 07 – Final Evaluation, Model Comparison & Conclusion\n",
    "\n",
    "*Summarise performance of every iteration and decide which model ships to production.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42ab8e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np, matplotlib.pyplot as plt, seaborn as sns, pandas as pd\n",
    "from src.evaluation import evaluate\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e97c0e",
   "metadata": {},
   "source": [
    "## 1  Collect validation metrics from each notebook\n",
    "\n",
    "Below we hard-code the best validation accuracy, precision & F1 that each model achieved  \n",
    "(you can pull them automatically if you saved `history` objects).  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a74daaeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {\n",
    "    \"Baseline-majority\":  {\"acc\": 0.66, \"f1_rec\": None, \"f1_non\": None},\n",
    "    \"V1 MLP\":            {\"acc\": 0.79, \"f1_rec\": 0.80, \"f1_non\": 0.77},\n",
    "    \"V2 CNN\":            {\"acc\": 0.86, \"f1_rec\": 0.87, \"f1_non\": 0.85},\n",
    "    \"V3 ResNet50\":       {\"acc\": 0.94, \"f1_rec\": 0.94, \"f1_non\": 0.93},\n",
    "    \"V4 Aug CNN\":        {\"acc\": 0.91, \"f1_rec\": 0.91, \"f1_non\": 0.89},\n",
    "}\n",
    "df = pd.DataFrame(results).T\n",
    "df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2020724e",
   "metadata": {},
   "source": [
    "## 2  Accuracy bar-chart\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3196c347",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,4))\n",
    "sns.barplot(x=df.index, y=df[\"acc\"], palette=\"viridis\")\n",
    "plt.xticks(rotation=25); plt.ylim(0.6,1)\n",
    "plt.ylabel(\"validation accuracy\"); plt.title(\"Model comparison\")\n",
    "for i,v in enumerate(df[\"acc\"]):\n",
    "    plt.text(i, v+0.01, f\"{v:.2f}\", ha=\"center\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "909423f0",
   "metadata": {},
   "source": [
    "## 3  Best confusion matrix (ResNet50)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17455f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you saved the trained ResNet model as .h5 or kept it in memory, load here:\n",
    "# from tensorflow.keras.models import load_model\n",
    "# best_model = load_model(\"../models/resnet50_best.h5\")\n",
    "\n",
    "# Otherwise just re-assign from notebook 04 variable if still in RAM\n",
    "best_model   = resnet        # <-- rename if different\n",
    "X_val_images = X_val         # <-- pick the same validation set used in notebook 04\n",
    "y_val_hot    = y_val\n",
    "\n",
    "cm = evaluate(best_model, X_val_images, y_val_hot,\n",
    "              labels=[\"recyclable\", \"non-recyclable\"])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f3457af",
   "metadata": {},
   "source": [
    "## 4  Summary & Recommendation\n",
    "\n",
    "* **ResNet50 (frozen) wins** with **94 %** validation accuracy and balanced F1 scores.  \n",
    "* The augmented CNN (V4) is close (91 %) with 10 × fewer parameters → candidate for edge deployment.  \n",
    "* Error analysis (nb. 06) showed residual confusion in non-recyclable items caused by texture blur and multiple small objects.\n",
    "\n",
    "### Next steps\n",
    "1. Collect 500 high-quality non-recyclable images to balance subclasses.  \n",
    "2. Fine-tune upper 20 layers of ResNet50 at lr = 1e-5 for potential +1 % accuracy.  \n",
    "3. Integrate Grad-CAM heatmaps into operator dashboard for transparency.\n",
    "\n",
    "*Decision*: **Ship ResNet50 TL** for first pilot at WMCN’s Utrecht facility, keep Aug-CNN as edge fallback.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
